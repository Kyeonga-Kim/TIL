{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-9ab6343fe775>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000128CEEC3908>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000128CF6E0448>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x00000128CF6E0688>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32, [None,784])\n",
    "y=tf.placeholder(tf.float32, [None,10])\n",
    "w=tf.Variable(tf.random_normal([784,10]))\n",
    "b=tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf=tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "cost=tf.reduce_mean(-tf.reduce_sum(y*tf.log(hf), axis=1))\n",
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCorrect=tf.equal(tf.argmax(hf,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(isCorrect,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs=15\n",
    "batchsize=100\n",
    "numIter=int(mnist.train.num_examples/batchsize) #60000/100=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭:0001, cost:2.826302752\n",
      "에폭:0002, cost:1.061668976\n",
      "에폭:0003, cost:0.838061328\n",
      "에폭:0004, cost:0.733232746\n",
      "에폭:0005, cost:0.669279894\n",
      "에폭:0006, cost:0.624611839\n",
      "에폭:0007, cost:0.591160358\n",
      "에폭:0008, cost:0.563868996\n",
      "에폭:0009, cost:0.541745189\n",
      "에폭:0010, cost:0.522673595\n",
      "에폭:0011, cost:0.506782334\n",
      "에폭:0012, cost:0.492447652\n",
      "에폭:0013, cost:0.479955845\n",
      "에폭:0014, cost:0.468893677\n",
      "에폭:0015, cost:0.458703488\n",
      "정확도: 0.8951\n",
      "레이블: [7]\n",
      "예측: [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #트레이닝\n",
    "    for epoch in range(numEpochs):#15에폭\n",
    "        avgCv=0\n",
    "        for i in range(numIter): #600\n",
    "            batchX,batchY=mnist.train.next_batch(batchsize)\n",
    "            _,cv=sess.run([train,cost], feed_dict={x:batchX,y:batchY})\n",
    "            avgCv+=cv/numIter\n",
    "        print(\"에폭:{:04d}, cost:{:.9f}\".format(epoch+1,avgCv))\n",
    "    print(\"정확도:\", accuracy.eval(session=sess, feed_dict={x:mnist.test.images, y:mnist.test.labels}))\n",
    "    r=random.randint(0,mnist.test.num_examples-1)\n",
    "    print(\"레이블:\",sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n",
    "    print(\"예측:\", sess.run(tf.argmax(hf,1),feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),\n",
    "              cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#학습 모델 저장/불러오기 (keras)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, yTrain), (xTest,yTest)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "xTrain=xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain=np_utils.to_categorical(yTrain)\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest=np_utils.to_categorical(yTest)\n",
    "yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal=xTrain[42000:]\n",
    "xTrain=xTrain[:42000]\n",
    "yVal=yTrain[42000:]\n",
    "yTrain=yTrain[:42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#모델 구성\n",
    "model=Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation=\"relu\"))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 1.0003 - accuracy: 0.7444 - val_loss: 0.5205 - val_accuracy: 0.8702\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 1s 26us/step - loss: 0.4540 - accuracy: 0.8806 - val_loss: 0.3925 - val_accuracy: 0.8926\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 1s 26us/step - loss: 0.3753 - accuracy: 0.8965 - val_loss: 0.3477 - val_accuracy: 0.9027\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.3393 - accuracy: 0.9045 - val_loss: 0.3233 - val_accuracy: 0.9099\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 0.3167 - accuracy: 0.9106 - val_loss: 0.3074 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x128d0f38c88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습 환경 설정(compile)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])\n",
    "#학습(fit)\n",
    "model.fit(xTrain,yTrain,epochs=5, batch_size=50,validation_data=(xVal,yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 12us/step\n",
      "평가결과:[0.2958790455106646, 0.9162999987602234]\n"
     ]
    }
   ],
   "source": [
    "#모델 평가하기(test data)\n",
    "metrics=model.evaluate(xTest,yTest,batch_size=50)\n",
    "print(\"평가결과:\"+str(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.random.choice(xTest.shape[0],5)\n",
    "xHat=xTest[idx]\n",
    "yHat=model.predict_classes(xHat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 : 9 실제값 : 9\n",
      "예측값 : 0 실제값 : 0\n",
      "예측값 : 5 실제값 : 5\n",
      "예측값 : 3 실제값 : 3\n",
      "예측값 : 4 실제값 : 4\n"
     ]
    }
   ],
   "source": [
    "#print(\"예측값:\",yHat) #예측값\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"예측값 : \"+ str(yHat[i]) + \" 실제값 : \"+str(np.argmax(yTest[idx[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_model.h5') #케라스 모델 저장함수(아키테쳐+가중치) = .h5로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 아키텍쳐 확인\n",
    "# import keras\n",
    "# import pydot as pyd\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "# from IPython.display import SVG\n",
    "\n",
    "# keras.utils.vis_utils.pydot = pyd\n",
    "\n",
    "# SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 : 0 실제값 : 0\n",
      "예측값 : 7 실제값 : 7\n",
      "예측값 : 9 실제값 : 9\n",
      "예측값 : 4 실제값 : 5\n",
      "예측값 : 4 실제값 : 4\n",
      "예측값 : 7 실제값 : 7\n",
      "예측값 : 0 실제값 : 0\n",
      "예측값 : 9 실제값 : 9\n",
      "예측값 : 9 실제값 : 9\n",
      "예측값 : 2 실제값 : 2\n"
     ]
    }
   ],
   "source": [
    "#실제 데이터 사용\n",
    "\n",
    "(xTrain, yTrain), (xTest,yTest)=mnist.load_data()\n",
    "xTest = xTest.reshape(10000,784).astype('float32')\n",
    "yTest = np_utils.to_categorical(yTest)\n",
    "idx = np.random.choice(xTest.shape[0],10)\n",
    "xhat = xTest[idx]\n",
    "\n",
    "#모델 불러오기\n",
    "from keras.models import load_model\n",
    "model = load_model('mnist_model.h5')\n",
    "yhat=model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"예측값 : \"+ str(yhat[i]) + \" 실제값 : \"+str(np.argmax(yTest[idx[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,4])\n",
    "y = tf.placeholder(tf.float32,shape=[None,1])\n",
    "\n",
    "w=tf.Variable(tf.random_normal([4,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hf=tf.matmul(x,w)+b\n",
    "cost=tf.reduce_mean(tf.square(hf-y)) #regression문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.train.GradientDescentOptimizer(1e-5).minimize(cost)\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 68239850000.0 Prediction: [[-183954.67]\n",
      " [-369512.62]\n",
      " [-290846.9 ]\n",
      " [-204112.56]\n",
      " [-240421.47]\n",
      " [-242438.39]\n",
      " [-222261.36]\n",
      " [-282769.78]]\n",
      "1 Cost: 7.4973665e+25 Prediction: [[6.1078126e+12]\n",
      " [1.2295653e+13]\n",
      " [9.6725463e+12]\n",
      " [6.7804033e+12]\n",
      " [7.9910682e+12]\n",
      " [8.0583270e+12]\n",
      " [7.3857358e+12]\n",
      " [9.4035090e+12]]\n",
      "2 Cost: inf Prediction: [[-2.0245169e+20]\n",
      " [-4.0755599e+20]\n",
      " [-3.2060957e+20]\n",
      " [-2.2474561e+20]\n",
      " [-2.6487473e+20]\n",
      " [-2.6710411e+20]\n",
      " [-2.4481017e+20]\n",
      " [-3.1169198e+20]]\n",
      "3 Cost: inf Prediction: [[6.7105335e+27]\n",
      " [1.3508992e+28]\n",
      " [1.0627036e+28]\n",
      " [7.4494959e+27]\n",
      " [8.7796296e+27]\n",
      " [8.8535257e+27]\n",
      " [8.1145627e+27]\n",
      " [1.0331451e+28]]\n",
      "4 Cost: inf Prediction: [[-2.2242970e+35]\n",
      " [-4.4777377e+35]\n",
      " [-3.5224746e+35]\n",
      " [-2.4692362e+35]\n",
      " [-2.9101269e+35]\n",
      " [-2.9346206e+35]\n",
      " [-2.6896814e+35]\n",
      " [-3.4244991e+35]]\n",
      "5 Cost: inf Prediction: [[inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]\n",
      " [inf]]\n",
      "6 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 Cost: nan Prediction: [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(101):\n",
    "    cv,hv,_= sess.run([cost, hf, train], feed_dict={x:xdata, y:ydata})\n",
    "    print(step, \"Cost:\",cv, \"Prediction:\",hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#트레이닝 횟수 : 10000번,Ir=0.1\n",
    "#예측값 출력\n",
    "#0 0 => 0\n",
    "#0 1 => 1\n",
    "y_data = np.array([[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]])\n",
    "\n",
    "xdata=y_data[:,0:-1]\n",
    "ydata=y_data[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 2)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape)\n",
    "print(ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32, shape=[None,2])\n",
    "y=tf.placeholder(tf.float32, shape=[None,1])\n",
    "hf=tf.sigmoid(tf.matmul(x,w)+b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(tf.random_normal([2,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "\n",
    "predicted=tf.cast(hf>0.7, dtype=tf.float32)\n",
    "\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 1.0591345\n",
      "100 cost: 0.62173724\n",
      "200 cost: 0.45034343\n",
      "300 cost: 0.34112996\n",
      "400 cost: 0.26903075\n",
      "500 cost: 0.2193935\n",
      "600 cost: 0.1838086\n",
      "700 cost: 0.1573691\n",
      "800 cost: 0.1371147\n",
      "900 cost: 0.12119104\n",
      "1000 cost: 0.10839459\n",
      "1100 cost: 0.097917\n",
      "1200 cost: 0.08919954\n",
      "1300 cost: 0.08184549\n",
      "1400 cost: 0.07556654\n",
      "1500 cost: 0.07014877\n",
      "1600 cost: 0.06543048\n",
      "1700 cost: 0.061287127\n",
      "1800 cost: 0.05762189\n",
      "1900 cost: 0.054358076\n",
      "2000 cost: 0.051434435\n",
      "2100 cost: 0.04880125\n",
      "2200 cost: 0.046418082\n",
      "2300 cost: 0.044251405\n",
      "2400 cost: 0.042273503\n",
      "2500 cost: 0.04046113\n",
      "2600 cost: 0.038794518\n",
      "2700 cost: 0.0372571\n",
      "2800 cost: 0.035834543\n",
      "2900 cost: 0.034514673\n",
      "3000 cost: 0.03328681\n",
      "3100 cost: 0.032141827\n",
      "3200 cost: 0.031071631\n",
      "3300 cost: 0.030069321\n",
      "3400 cost: 0.029128611\n",
      "3500 cost: 0.02824409\n",
      "3600 cost: 0.027410865\n",
      "3700 cost: 0.026624728\n",
      "3800 cost: 0.025881788\n",
      "3900 cost: 0.025178602\n",
      "4000 cost: 0.024512075\n",
      "4100 cost: 0.023879517\n",
      "4200 cost: 0.023278402\n",
      "4300 cost: 0.022706354\n",
      "4400 cost: 0.022161407\n",
      "4500 cost: 0.02164176\n",
      "4600 cost: 0.021145578\n",
      "4700 cost: 0.02067145\n",
      "4800 cost: 0.020217804\n",
      "4900 cost: 0.01978349\n",
      "5000 cost: 0.019367218\n",
      "5100 cost: 0.018967912\n",
      "5200 cost: 0.01858458\n",
      "5300 cost: 0.018216262\n",
      "5400 cost: 0.017862113\n",
      "5500 cost: 0.017521353\n",
      "5600 cost: 0.017193262\n",
      "5700 cost: 0.01687706\n",
      "5800 cost: 0.016572172\n",
      "5900 cost: 0.016278043\n",
      "6000 cost: 0.015994132\n",
      "6100 cost: 0.015719779\n",
      "6200 cost: 0.015454648\n",
      "6300 cost: 0.015198182\n",
      "6400 cost: 0.014950026\n",
      "6500 cost: 0.014709812\n",
      "6600 cost: 0.014477153\n",
      "6700 cost: 0.014251628\n",
      "6800 cost: 0.014032995\n",
      "6900 cost: 0.013820926\n",
      "7000 cost: 0.013615057\n",
      "7100 cost: 0.013415251\n",
      "7200 cost: 0.013221166\n",
      "7300 cost: 0.0130326\n",
      "7400 cost: 0.0128492545\n",
      "7500 cost: 0.01267097\n",
      "7600 cost: 0.012497551\n",
      "7700 cost: 0.012328732\n",
      "7800 cost: 0.012164449\n",
      "7900 cost: 0.012004435\n",
      "8000 cost: 0.011848514\n",
      "8100 cost: 0.011696601\n",
      "8200 cost: 0.011548529\n",
      "8300 cost: 0.011404144\n",
      "8400 cost: 0.011263262\n",
      "8500 cost: 0.011125792\n",
      "8600 cost: 0.01099161\n",
      "8700 cost: 0.010860663\n",
      "8800 cost: 0.010732739\n",
      "8900 cost: 0.010607768\n",
      "9000 cost: 0.010485671\n",
      "9100 cost: 0.010366309\n",
      "9200 cost: 0.010249669\n",
      "9300 cost: 0.010135502\n",
      "9400 cost: 0.010023965\n",
      "9500 cost: 0.009914764\n",
      "9600 cost: 0.009807942\n",
      "9700 cost: 0.0097033875\n",
      "9800 cost: 0.00960097\n",
      "9900 cost: 0.0095007485\n",
      "10000 cost: 0.009402617\n",
      "hypothesis: [[0.98614216]\n",
      " [0.98614216]\n",
      " [0.98614216]\n",
      " [0.0055314 ]\n",
      " [0.0055314 ]\n",
      " [0.0055314 ]\n",
      " [0.00831929]\n",
      " [0.00831929]] prediction: [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv,_ = sess.run([cost,train], feed_dict={x:xdata,y:ydata})\n",
    "        if step % 100 ==0:\n",
    "            print(step,\"cost:\",cv)\n",
    "    hv,pv,av=sess.run([hf, predicted, accuracy], feed_dict={x:xdata, y:ydata})\n",
    "    print(\"hypothesis:\", hv,\"prediction:\", pv, \"accuracy:\", av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
